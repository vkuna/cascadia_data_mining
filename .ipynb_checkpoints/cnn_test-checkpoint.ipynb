{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Thought Experiment\n",
    "\n",
    "You've gone back in time to the year 2010 to work as a programmer. Your boss tells you to write a \"simple\" program to tell the difference between pictures of Turkey's and Iguana's. How do you do it?\n",
    "\n",
    "|Turkey | Iguana |\n",
    "| -| -|\n",
    "| <img src=https://raw.githubusercontent.com/jsearcy1/racsml/develop/assets/Turkey.jpg width=\"500\"> | <img src=https://raw.githubusercontent.com/jsearcy1/racsml/develop/assets/iguana.jpg width=\"540\"  >|\n",
    "\n",
    "\n",
    "You've been studying ML so you know how to use an normal (dense) artificial neural network.\n",
    "\n",
    "<img src=https://raw.githubusercontent.com/jsearcy1/racsml/master/assets/network_diagrams/nn_3_3_1.png>\n",
    "\n",
    "this network uses features to classify instances between two groups. \n",
    "\n",
    "## What Features would you use to classify these images?\n",
    "   * Feathers\n",
    "   * Scales\n",
    "   * Other Ideas?\n",
    "  \n",
    "   \n",
    "\n",
    "\n",
    "## How do you find these features in an image?\n",
    "\n",
    "Their are a tone of techniques that have been developed to help for this for example you could use a difference of Gaussians edge detector, to look Turkey feathers. \n",
    "\n",
    "<img src=https://micro.magnet.fsu.edu/primer/java/digitalimaging/processing/diffgaussians/diffgaussiansfigure1.jpg alt=\"source /https://micro.magnet.fsu.edu/primer/java/digitalimaging/processing/diffgaussians/index.html \">\n",
    "\n",
    "\n",
    "\n",
    "| |  |\n",
    "| -| -|\n",
    "| <img src=https://raw.githubusercontent.com/jsearcy1/racsml/develop/assets/Turkey_edge.jpg width=\"500\"> | <img src=https://raw.githubusercontent.com/jsearcy1/racsml/develop/assets/iguana_edge.jpg width=\"540\"  >|\n",
    "\n",
    "\n",
    "You could just count the number of edge pixels and get a feature for you ANN, but it might not be a very good feature because this edge detector highlights turkey feathers, but also things like leaves.\n",
    "\n",
    "You can keep working on new techniques and adding new features until you get a system that starts to work. This is normally called to 'feature engineering' which underlies a lot of traditional machine vision techniques.\n",
    "\n",
    "## Deep Learning\n",
    "\n",
    "After months of feature engineering you might start thinking that there maybe an easier way. \n",
    "\n",
    "**Why not build something that can learn the features from our images just like our ANNs learn which features are most important**\n",
    "\n",
    "At this point you as a time traveling programmer would probably track down Yann LeCun to start learning about convolutional neural networks (CNN) and dive into deep-learning. As a bonus you could go win the Image-Net Challenge. \n",
    "\n",
    "\n",
    "\n",
    "### ImageNet Error Rate\n",
    "<img src=https://www.researchgate.net/profile/Frank_E_Curtis/publication/303992986/figure/fig7/AS:667038804615177@1536045852897/Historical-top5-error-rate-of-the-annual-winner-of-the-ImageNet-image-classification.png  alt=\" source https://www.researchgate.net/publication/303992986_Optimization_Methods_for_Large-Scale_Machine_Learning\"> \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What does this have to do with Earthquakes?\n",
    "\n",
    "Like in Machine Vision there are also methods relying on Feature Engineering for example\n",
    "\n",
    "* Long Term Average/Short Term Average\n",
    "\n",
    "Very similar to the difference in gaussians feature above, used for triggering earthquakes in sesmigraph data.\n",
    "\n",
    "\n",
    "\n",
    "<img src=http://www.geopsy.org/wiki/images/STALTAWin.png>\n",
    "\n",
    "\n",
    "Can deep-learning do better?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks\n",
    "Deep Learning is a lot like using Legos. You have different pieces (or in this case layers) that can be combined anyway you want to build something useful. There are also a lot of ways of putting the pieces together that don't do anything at all, so it's important to understand your layers.\n",
    "\n",
    "## Layers for Convolutional Neural Networks\n",
    "\n",
    "1. A Dense layer (Just and ANN like you've seen before)\n",
    "    * Used at the end for classification/regression tasks\n",
    "2. Convolutional Layers\n",
    "    * These are today's new layers that can learn features\n",
    "3. Pooling Layers\n",
    "    * These are layers are simple and reduce the size of of the last layer\n",
    "    * Often you'll see a \"MaxPool\" layer that just returns the maximum value in a window (normally size 2)\n",
    "    \n",
    "4. Activations\n",
    "    * Often these are considered a part of Dense and CNN layers, but they can also be included as layers themselves\n",
    "    \n",
    "## An Example Network\n",
    "\n",
    "A common way of putting these layers together is a pyramid. Alternating the feature learning convolutional layers with size reducing pooling layers. Ending in a dense layer for classification.\n",
    "\n",
    "<img src=\"https://pythonmachinelearning.pro/wp-content/uploads/2017/09/lenet-5.png\" alt=\"source https://pythonmachinelearning.pro/introduction-to-convolutional-neural-networks-for-vision-tasks/\">\n",
    "\n",
    "### Why use a pyramid\n",
    "\n",
    "* Fewer parameters required\n",
    "    * Dense layers in particular require a huge number of parameters when using on large input data, for example millions of pixels or thousands of seimicgraph traces\n",
    "\n",
    "* Richer Features\n",
    "    * We will talk about this more, but imagine the edge finder above, edges alone may not tell you much, but edges can be combined into textures, eyes, beaks, by lower layers for more useful features \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# A 2 Dimensional Convolutional Filter\n",
    "\n",
    "<img src=2D_CNN.jpg>\n",
    "\n",
    "## What you can control\n",
    "### Box Size\n",
    "Above is a 3x3 box which is common, but be adjusting using the Kernel Size Argument\n",
    " \n",
    "### Stride\n",
    "How many pixels your box steps at a time a 1 pixel step will produced an output with the same size as the input image (if padding is correct see below). A stride of 2 will step 2 pixels each time resulting in an output about 1/2 the size of the input\n",
    "* Generally a stride should be smaller than the kernel (box) size\n",
    "* Generally it should be an integer divisor\n",
    "\n",
    "### Padding\n",
    "If you want to preserve the input size of your image, you'll need to use a stride of one you'll also need to use some zero padding (adding zeros to make the image lager). This is because the first and last pixel in each row and column doesn't have any neighboring values to multiply by the weight. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 1D - Data\n",
    "\n",
    "\n",
    "Time series with many channels\n",
    "\n",
    "<img src=https://prd-wret.s3.us-west-2.amazonaws.com/assets/palladium/production/s3fs-public/styles/full_width/public/thumbnails/image/IRIS-SPUD-waveforms.png>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-D Convolutional Neural Networks\n",
    "Same as 2D convolutions but instead of 2d boxes sliding across the data, we slide 1-d windows.\n",
    "\n",
    "\n",
    "<p style=\"text-align: center;\">\n",
    "Output <br>\n",
    "    \n",
    "<img src=\"http://cs231n.github.io/assets/cnn/stride.jpeg\">\n",
    "<br>\n",
    "Input\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is stride used above in each example?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's write some code\n",
    "* We will write the model in keras/tensorflow\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/amt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/amt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/amt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/amt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/amt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Fri Oct 11 15:48:23 2019\n",
    "\n",
    "@author: jsearcy\n",
    "\n",
    "\n",
    "https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2017JB015251\n",
    "p-wave pick\n",
    "\"\"\"\n",
    "\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our layers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_layer=tf.keras.layers.Input(shape=(400,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn=tf.keras.layers.Conv1D(64,10,1,padding='same',activation='relu',input_shape=(None,400,1)) # N filters, Filter Size, Stride,padding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense=tf.keras.layers.Dense(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation=tf.keras.layers.Activation('sigmoid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stick the legos together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output= activation( dense (cnn(in_layer)))\n",
    "model=tf.keras.models.Model(in_layer,output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the dimension of each layer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss and Optimizer\n",
    "\n",
    "Like any ML model you'll need to tell it what to do in this case will give this model a loss of mean squared error (\"mse\") and use the adam optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse',optimizer='adam')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Real Example\n",
    "As an example lets use the data and methods presented here:\n",
    "\n",
    "Journal of Geophysical Research: Solid Earth Research Article P Wave Arrival Picking and First‐Motion Polarity Determination With Deep Learning \n",
    "Zachary E. Ross, Men‐Andrin Meier, Egill Hauksson\n",
    "\n",
    "https://doi.org/10.1029/2017JB015251\n",
    "(2018)\n",
    "\n",
    "\n",
    "## Data \n",
    " * hdf5 files from the paper's author\n",
    " * Opened with h5py\n",
    "\n",
    "## Model\n",
    "* We will write the model in keras/tensorflow\n",
    "\n",
    "## Warning this data is large and will take some time to download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_data=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if download_data:\n",
    "    !wget https://service.scedc.caltech.edu/ftp/Ross_FinalTrainedModels/scsn_p_2000_2017_6sec_0.5r_pick_test.hdf5\n",
    "    !wget https://service.scedc.caltech.edu/ftp/Ross_FinalTrainedModels/scsn_p_2000_2017_6sec_0.5r_pick_test.hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the downloaded data if you have it Otherwise generate 'fake' data\n",
    "\n",
    "if os.path.exists('scsn_p_2000_2017_6sec_0.5r_pick_train.hdf5'):\n",
    "    train_data=h5py.File(\"scsn_p_2000_2017_6sec_0.5r_pick_train.hdf5\",'r')['X']\n",
    "    test_data=h5py.File(\"scsn_p_2000_2017_6sec_0.5r_pick_test.hdf5\",'r')['X']\n",
    "else:    \n",
    "    train_data=np.random.normal(0,0.25,(10000,600)) #4,000 examples of 600 time-steps\n",
    "    train_data[:,300:350]=train_data[:,300:350]*3 #This will be our 'earthquake'\n",
    "\n",
    "    test_data=np.random.normal(0,0.25,(10000,600)) #4,000 examples of 600 time-steps\n",
    "    test_data[:,300:350]=test_data[:,300:350]*3 #This will be our 'earthquake'\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_data[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The devil is in the details\n",
    "\n",
    "Writing an ML model is often the easy part of the process, most of the work often comes in setting up the data so you have the ML model answering the question you want it to\n",
    "\n",
    "* This data is 100 hz for 6 seconds has p-wave picks all are at 3 seconds \n",
    "* Asking the model to predict the arrival time isn't useful it will just say 3 seconds always\n",
    "* We want it to learn where the p-wave was\n",
    "    * Randomly offset by +/- 0.5 seconds, and try to predict the offset\n",
    "* Do generate this data we'll use a data python generator\n",
    "    * Generator will return one batch and its targets\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Python Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_number(max_value):\n",
    "    while True:\n",
    "        yield np.random.uniform(max_value)\n",
    "        yield(x,y)\n",
    "gen=random_number(100)\n",
    "    \n",
    "\n",
    "print(next(gen))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "p-wave picker\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def my_data_generator(batch_size,dataset):\n",
    "    while True:\n",
    "        start_of_batch=np.random.choice(dataset.shape[0]-batch_size)\n",
    "        \n",
    "        #HDF5 are slow if not read in continous chunks ('Batch Suffile')\n",
    "        batch=dataset[start_of_batch:start_of_batch+batch_size]\n",
    "        time_offset=np.random.uniform(-0.5,0.5,size=batch_size)\n",
    "        new_batch=[]\n",
    "            \n",
    "        \n",
    "        for i,offset in enumerate(time_offset):\n",
    "            bin_offset=int(offset*100) #HZ sampling Frequency\n",
    "            start_bin=100 - bin_offset # keep 4 s worth of samples\n",
    "            end_bin=500 - bin_offset # keep 4s worth of samples\n",
    "            assert(start_bin >=0)\n",
    "            assert(end_bin < 600)\n",
    "            new_batch.append(batch[i:i+1,start_bin:end_bin])\n",
    "        new_batch=np.concatenate(new_batch)\n",
    "        yield(new_batch,time_offset+2)\n",
    "    \n",
    "\n",
    "my_data=my_data_generator(32,train_data)\n",
    "                  \n",
    "x,y=next(my_data)\n",
    "print(x.shape,y.shape)\n",
    "print(y)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=https://raw.githubusercontent.com/jsearcy1/racsml/develop/assets/figure1.png>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#These models start with an input\n",
    "input_layer=tf.keras.layers.Input(shape=(400,)) # 1 Channel seismic data\n",
    "\n",
    "#These Convolutional blocks expect 2D data (time-steps x channels)\n",
    "#This is just one channel, but if you wanted to add more stations as extra channels you can\n",
    "\n",
    "network=tf.keras.layers.Reshape((400,1))(input_layer)\n",
    "\n",
    "#Here is your first convolution layer\n",
    "\n",
    "network=tf.keras.layers.Conv1D(32,21,activation='relu')(network)\n",
    "\n",
    "#This layer is a trick of the trade it helps training deeper networks, by keeping gradients close to the same scale\n",
    "\n",
    "network=tf.keras.layers.BatchNormalization()(network)\n",
    "#Max Pooling Layer\n",
    "\n",
    "network=tf.keras.layers.MaxPooling1D()(network)\n",
    "\n",
    "#Next Block\n",
    "network=tf.keras.layers.Conv1D(64,15,activation='relu')(network)\n",
    "network=tf.keras.layers.BatchNormalization()(network)\n",
    "network=tf.keras.layers.MaxPooling1D()(network)\n",
    "\n",
    "#Next Block\n",
    "network=tf.keras.layers.Conv1D(128,11,activation='relu')(network)\n",
    "network=tf.keras.layers.BatchNormalization()(network)\n",
    "network=tf.keras.layers.MaxPooling1D()(network)\n",
    "\n",
    "#Dense end of network\n",
    "\n",
    "network=tf.keras.layers.Flatten()(network)\n",
    "network=tf.keras.layers.Dense(512,activation='relu')(network)\n",
    "network=tf.keras.layers.BatchNormalization()(network)\n",
    "\n",
    "network=tf.keras.layers.Dense(512,activation='relu')(network)\n",
    "network=tf.keras.layers.BatchNormalization()(network)\n",
    "output=tf.keras.layers.Dense(1)(network)\n",
    "\n",
    "model=tf.keras.models.Model(input_layer,output)\n",
    "model.compile(loss='mse',optimizer='adam')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size=480\n",
    "\n",
    "history=model.fit_generator(my_data_generator(batch_size,train_data),\n",
    "                    steps_per_epoch=len(train_data)//batch_size,\n",
    "                    validation_data=my_data_generator(batch_size,test_data),\n",
    "                    validation_steps=len(test_data)//batch_size,\n",
    "                    epochs=10\n",
    "                   )\n",
    "model.save_weights(\"pick.tf\")\n",
    "                 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check how we did"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time =1\n",
    "offset=int((time-2)*100)\n",
    "\n",
    "f=plt.figure(figsize=(20,3))\n",
    "plt.plot(range(0,400),train_data[0,100-offset:500-offset])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"Some Predictions all offsets should be 2\")\n",
    "print(model.predict(train_data[0:10,100-offset:500-offset]))\n",
    "\n",
    "test_predictions=model.predict(test_data[:,100:500])-2\n",
    "plt.hist(test_predictions,range=(-.3,.3),bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# If you used the downloaded data compare against below\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From the Paper\n",
    "<img src=\"https://raw.githubusercontent.com/jsearcy1/racsml/develop/assets/jgrb52850-fig-0002-m.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
